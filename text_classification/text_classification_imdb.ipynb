{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd488f1",
   "metadata": {},
   "source": [
    "# Text classification IMDb\n",
    "\n",
    "Found it here:\n",
    "https://keras.io/examples/nlp/text_classification_from_scratch/\n",
    "\n",
    "Dataset:\n",
    "https://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d18086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec856d",
   "metadata": {},
   "source": [
    "### Gathering the data and spliting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca2bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e252a4bb",
   "metadata": {},
   "source": [
    "### Some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea2bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: b'This movie was well done in all respects. The acting is superb along with the fine audio soundtrack which I purchased because it was so moving. It is '...\n",
      "label: 1\n",
      "\n",
      "text: b'The first one was different and funny. This attempt should have never left the studio. This movie does not make you laugh. It is a weak attempt at gro'...\n",
      "label: 0\n",
      "\n",
      "text: b\"This was one of the most boring movies I've ever seen\\xc2\\x85 I don't really know why\\xc2\\x85 Just your run-of-the-mill stories about guy who is about to get marr\"...\n",
      "label: 0\n",
      "\n",
      "text: b'Her Deadly Rival (1995): Starring Harry Hamlin, Annie Potts, Lisa Zane, Tommy Hinkley, Susan Diol, Roma Maffia, Robert C. Treveiler, D. L. Anderson, W'...\n",
      "label: 1\n",
      "\n",
      "text: b'I saw the movie recently and really liked it. I surprised myself and cried. This movie is in the same niche genre as \"Away from Her\" - or even \"The Bu'...\n",
      "label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(\"text: \" + str(text_batch.numpy()[i][:150]) + \"...\")\n",
    "        print(\"label: \" + str(label_batch.numpy()[i]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933acf4",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "bye tags ðŸ‘‹ðŸ‘‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6f4e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# constants\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
